import streamlit as st
import base64
import time
from openai import OpenAI

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="å¤–å–çˆ†å•ç¥å™¨(ç¡…åŸºæµåŠ¨ç‰ˆ)", page_icon="ğŸ¨", layout="wide")

# CSS æ ·å¼
st.markdown("""
<style>
    .stApp { background-color: #FAFAFA; }
    .stButton>button { 
        background-color: #FF6B6B; color: white !important; 
        border-radius: 12px; padding: 12px 28px;
        font-size: 18px; font-weight: bold; width: 100%;
        border: none;
    }
    .stButton>button:hover { background-color: #FF5252; }
    #MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# --- 2. èº«ä»½éªŒè¯ ---
if "auth" not in st.session_state:
    st.session_state.auth = False

if not st.session_state.auth:
    c1, c2, c3 = st.columns([1,2,1])
    with c2:
        st.markdown("## ğŸ”’ å†…éƒ¨ç³»ç»Ÿç™»å½•")
        pwd = st.text_input("å¯†ç ", type="password", label_visibility="collapsed")
        if st.button("è§£é”"):
            if pwd == st.secrets.get("APP_PASSWORD", "123456"):
                st.session_state.auth = True
                st.rerun()
            else:
                st.error("âŒ å¯†ç é”™è¯¯")
    st.stop()

# --- 3. åå°é…ç½®åŠ è½½ ---
try:
    # A. æ–‡æœ¬ï¼šDeepSeek
    TEXT_KEY = st.secrets["DEEPSEEK_API_KEY"]
    TEXT_BASE = "https://api.deepseek.com"
    
    # B. è§†è§‰ï¼šKimi (Moonshot)
    VISION_KEY = st.secrets["MOONSHOT_API_KEY"]
    VISION_BASE = "https://api.moonshot.cn/v1"
    
    # C. ç»˜å›¾ï¼šç¡…åŸºæµåŠ¨ (SiliconFlow)
    IMG_KEY = st.secrets["SILICON_API_KEY"]
    IMG_BASE = "https://api.siliconflow.cn/v1"
    
except Exception as e:
    st.error(f"âŒ é…ç½®ç¼ºå¤±: {e}")
    st.info("è¯·åœ¨ Secrets ä¸­é…ç½® DEEPSEEK_API_KEY, MOONSHOT_API_KEY, SILICON_API_KEY")
    st.stop()

# --- 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def encode_image(uploaded_file):
    return base64.b64encode(uploaded_file.getvalue()).decode('utf-8')

def analyze_image_kimi(image_file):
    """ã€çœ¼ç›ã€‘Kimi çœ‹å›¾ (å¸¦é‡è¯•æœºåˆ¶)"""
    encoded_string = encode_image(image_file)
    client = OpenAI(api_key=VISION_KEY, base_url=VISION_BASE)
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="moonshot-v1-8k-vision-preview",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šç¾é£Ÿæ‘„å½±å¸ˆã€‚"},
                    {"role": "user", "content": [
                        {"type": "text", "text": "åˆ†æè¿™å¼ å›¾çš„èœå“ã€é£Ÿæã€è‰²æ³½ã€‚åªè¾“å‡ºå®¢è§‚æè¿°ã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded_string}"}}
                    ]}
                ]
            )
            return response.choices[0].message.content
        except Exception as e:
            if "429" in str(e) and attempt < max_retries - 1:
                st.toast(f"â³ Kimi æœåŠ¡å™¨ç¹å¿™ï¼Œæ­£åœ¨ç¬¬ {attempt+1} æ¬¡é‡è¯•...", icon="ğŸ”„")
                time.sleep(3)
                continue
            elif attempt == max_retries - 1:
                return f"è§†è§‰è¯†åˆ«å¤±è´¥: {str(e)}"

def generate_copy_deepseek(vision_res, user_topic):
    """ã€å¤§è„‘ã€‘DeepSeek å†™æ–‡"""
    client = OpenAI(api_key=TEXT_KEY, base_url=TEXT_BASE)
    prompt = f"""
    ä½ æ˜¯ä¸€åå°çº¢ä¹¦çˆ†æ¬¾å†™æ‰‹ã€‚è¯·ç»“åˆã€è§†è§‰æè¿°ã€‘å’Œã€å•†å®¶ä¿¡æ¯ã€‘ï¼Œå†™ä¸€ç¯‡å¤–å–ç§è‰ç¬”è®°ã€‚
    ã€è§†è§‰æè¿°ã€‘ï¼š{vision_res}
    ã€å•†å®¶ä¿¡æ¯ã€‘ï¼š{user_topic}
    è¦æ±‚ï¼šæ ‡é¢˜äºŒæç®¡ï¼Œæ­£æ–‡å¤šEmojiï¼Œè¯­æ°”çœŸè¯šã€‚
    """
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt}],
        temperature=1.3
    )
    return response.choices[0].message.content

def generate_image_silicon(vision_res, user_topic):
    """ã€ç”»æ‰‹ã€‘ç¡…åŸºæµåŠ¨ (è°ƒç”¨ Kolors å¯å›¾)"""
    
    # 1. å…ˆæŠŠæè¿°ä¼˜åŒ–æˆç»˜ç”» Prompt
    client_text = OpenAI(api_key=TEXT_KEY, base_url=TEXT_BASE)
    prompt_res = client_text.chat.completions.create(
        model="deepseek-chat",
        messages=[{
            "role": "user", 
            "content": f"æ ¹æ®æè¿°ï¼š'{vision_res}' å’Œå–ç‚¹ '{user_topic}'ï¼Œå†™ä¸€ä¸ªç®€çŸ­çš„AIç»˜ç”»æç¤ºè¯ï¼ˆä¸­æ–‡ï¼‰ã€‚åŒ…å«ï¼šç¾é£Ÿæ‘„å½±ã€8ké«˜æ¸…ã€ç‰¹å†™ã€å…‰æ³½æ„Ÿã€‚ç›´æ¥è¾“å‡ºæç¤ºè¯ã€‚"
        }]
    )
    draw_prompt = prompt_res.choices[0].message.content

    # 2. è°ƒç”¨ç”»å›¾ API
    client_img = OpenAI(api_key=IMG_KEY, base_url=IMG_BASE)
    
    try:
        response = client_img.images.generate(
            model="Kwai-Kolors/Kolors", # æŒ‡å®šä½¿ç”¨å¯å›¾ (æ•ˆæœæœ€åƒå¯çµ)
            # å¦‚æœæƒ³ç”¨ FLUXï¼Œå¯ä»¥æ”¹æˆ: "black-forest-labs/FLUX.1-schnell"
            prompt=draw_prompt,
            size="1024x1024",
            n=1
        )
        return response.data[0].url
    except Exception as e:
        return f"Error: {str(e)}"

# --- 5. ä¸»ç•Œé¢ ---

st.title("ğŸ¨ å¤–å–çˆ†å•ç¥å™¨ (ç¡…åŸºæµåŠ¨ç‰ˆ)")
st.caption("Kimi è§†è§‰ Â· DeepSeek æ–‡æ¡ˆ Â· Kolors ç»˜å›¾")

c1, c2 = st.columns([1, 1], gap="large")

with c1:
    st.markdown("#### 1. ä¸Šä¼ å®æ‹å›¾")
    uploaded_file = st.file_uploader("", type=["jpg", "png"], label_visibility="collapsed")
    if uploaded_file:
        st.image(uploaded_file, caption="åŸå›¾", use_container_width=True)

with c2:
    st.markdown("#### 2. è¡¥å……å–ç‚¹")
    user_topic = st.text_area("", height=150, placeholder="ä¾‹å¦‚ï¼šæ‹›ç‰Œçº¢çƒ§è‚‰ï¼Œè‚¥è€Œä¸è…»...", label_visibility="collapsed")
    
    st.write("")
    if st.button("ğŸš€ å‘¼å« AI æ¢¦ä¹‹é˜Ÿå¼€å§‹åˆ›ä½œ"):
        if not uploaded_file:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å›¾ç‰‡")
        else:
            with st.status("âš¡ AI å…¨é€Ÿè¿è½¬ä¸­...", expanded=True):
                
                st.write("ğŸ‘ï¸ Kimi æ­£åœ¨è¯†åˆ«å›¾ç‰‡ç»†èŠ‚...")
                vision_res = analyze_image_kimi(uploaded_file)
                if "å¤±è´¥" in vision_res: st.error(vision_res); st.stop()
                
                st.write("ğŸ§  DeepSeek æ­£åœ¨æ’°å†™æ–‡æ¡ˆ...")
                note_res = generate_copy_deepseek(vision_res, user_topic)
                
                st.write("ğŸ¨ å¯å›¾ (Kolors) æ­£åœ¨ç»˜åˆ¶ç¾é£Ÿå¤§ç‰‡...")
                img_res = generate_image_silicon(vision_res, user_topic)
                
            st.success("âœ… å®Œæˆï¼")
            
            r1, r2 = st.columns(2)
            with r1:
                st.markdown("### ğŸ–¼ï¸ ç²¾ä¿®ç”Ÿæˆå›¾")
                if "http" in img_res:
                    st.image(img_res, use_container_width=True)
                else:
                    st.error(img_res)
            with r2:
                st.markdown("### ğŸ“ çˆ†æ¬¾æ–‡æ¡ˆ")
                with st.container(border=True, height=500):
                    st.markdown(note_res)
