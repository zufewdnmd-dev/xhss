import streamlit as st
import base64
from openai import OpenAI

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="å¤–å–çˆ†å•ç¥å™¨(å¤šæ¨¡æ€ç»ˆæç‰ˆ)", page_icon="ğŸ”¥", layout="wide")

# æ³¨å…¥é«˜å®š CSS æ ·å¼
st.markdown("""
<style>
    .stApp { background-color: #F8F5F2; } /* æŸ”å’Œç±³ç™½ */
    h1, h2, h3 { color: #2C3E50 !important; font-family: 'Helvetica Neue', sans-serif; }
    .stButton>button { 
        background-color: #FF6B6B; 
        color: white !important; 
        border-radius: 12px; 
        border: none;
        padding: 10px 24px;
        font-weight: bold;
        transition: all 0.3s;
    }
    .stButton>button:hover { background-color: #FF4757; transform: scale(1.02); }
    .reportview-container .main .block-container { max-width: 1200px; }
</style>
""", unsafe_allow_html=True)

# --- 2. å®‰å…¨éªŒè¯ä¸é…ç½® ---
def check_auth():
    if "auth" not in st.session_state:
        st.session_state.auth = False
    
    # ä¾§è¾¹æ é…ç½®åŒº
    with st.sidebar:
        st.title("âš™ï¸ æ§åˆ¶å°")
        
        # 1. è®¿é—®å¯†ç 
        if not st.session_state.auth:
            pwd = st.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password")
            if pwd == st.secrets.get("APP_PASSWORD", "123456"):
                st.session_state.auth = True
                st.rerun()
            else:
                st.warning("ğŸ”’ æœªè§£é”")
                st.stop()
        
        st.success("âœ… å·²è§£é”")
        st.divider()
        
        # 2. æ¨¡å‹é…ç½® (æ”¯æŒåˆ†åˆ«é…ç½®ï¼Œè¿½æ±‚æœ€ä½³æ•ˆæœ)
        st.markdown("### ğŸ§  æ¨¡å‹é…ç½®")
        
        # A. è§†è§‰æ¨¡å‹ (çœ¼ç›) - å»ºè®® GPT-4o æˆ– Qwen-VL
        vision_provider = st.selectbox("ğŸ‘ï¸ è§†è§‰æ¨¡å‹ (è´Ÿè´£çœ‹å›¾)", ["OpenAI (GPT-4o)", "Aliyun (é€šä¹‰åƒé—®VL)", "è‡ªå®šä¹‰"])
        vision_key = st.text_input("Vision API Key", type="password", value=st.secrets.get("VISION_API_KEY", ""))
        
        # B. æ–‡æœ¬æ¨¡å‹ (å¤§è„‘) - å»ºè®® DeepSeek
        text_provider = st.selectbox("ğŸ“ æ–‡æœ¬æ¨¡å‹ (è´Ÿè´£å†™æ–‡)", ["DeepSeek-V3", "Moonshot (Kimi)", "OpenAI"])
        text_key = st.text_input("Text API Key", type="password", value=st.secrets.get("DEEPSEEK_API_KEY", ""))
        
        # C. ç»˜å›¾æ¨¡å‹ (æ‰‹) - å»ºè®® SiliconFlow FLUX
        img_provider = st.selectbox("ğŸ¨ ç»˜å›¾æ¨¡å‹ (è´Ÿè´£ä¿®å›¾)", ["SiliconFlow (FLUX.1)"])
        img_key = st.text_input("Image API Key", type="password", value=st.secrets.get("SILICON_API_KEY", ""))

        return {
            "vision": (vision_provider, vision_key),
            "text": (text_provider, text_key),
            "img": (img_provider, img_key)
        }

config = check_auth()

# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def encode_image(uploaded_file):
    """å°†å›¾ç‰‡è½¬ä¸º Base64 ä¾› AI è§‚çœ‹"""
    return base64.b64encode(uploaded_file.getvalue()).decode('utf-8')

def analyze_image(image_file, provider_config):
    """ã€çœ¼ç›ã€‘è§†è§‰åˆ†æï¼šè°ƒç”¨å¤šæ¨¡æ€æ¨¡å‹çœ‹å›¾"""
    provider, key = provider_config
    if not key: return "Error: æœªé…ç½®è§†è§‰ API Key"
    
    base64_image = encode_image(image_file)
    
    # è®¾ç½® API ç«¯ç‚¹ (æ ¹æ®é€‰æ‹©è°ƒæ•´)
    if "OpenAI" in provider:
        base_url, model = "https://api.openai.com/v1", "gpt-4o"
    elif "Aliyun" in provider:
        base_url, model = "https://dashscope.aliyuncs.com/compatible-mode/v1", "qwen-vl-max"
    else:
        base_url, model = "https://api.openai.com/v1", "gpt-4o" # é»˜è®¤å›é€€

    client = OpenAI(api_key=key, base_url=base_url)
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "è¯·ç”¨ä¸“ä¸šçš„æ‘„å½±å¸ˆè§†è§’è¯¦ç»†æè¿°è¿™å¼ ç¾é£Ÿå›¾ç‰‡ã€‚åŒ…å«ï¼šèœå“åç§°ã€ä¸»è¦é£Ÿæã€è‰²æ³½ã€æ‘†ç›˜æ„å›¾ã€å…‰çº¿æ°›å›´ã€‚å¦‚æœä½ è§‰å¾—å›¾ç‰‡ä¸å¤Ÿå¥½ï¼Œè¯·æŒ‡å‡ºéœ€è¦æ”¹è¿›çš„åœ°æ–¹ï¼ˆå¦‚å…‰çº¿å¤ªæš—ã€æ„å›¾æ‚ä¹±ï¼‰ã€‚åªè¾“å‡ºæè¿°ï¼Œä¸è¦åºŸè¯ã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                    ],
                }
            ],
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"è§†è§‰è¯†åˆ«å¤±è´¥: {str(e)}"

def generate_copy(vision_analysis, user_topic, provider_config):
    """ã€å¤§è„‘ã€‘æ–‡æ¡ˆç”Ÿæˆï¼šDeepSeek ç»“åˆè§†è§‰ä¿¡æ¯å†™æ–‡"""
    provider, key = provider_config
    if not key: return "Error: æœªé…ç½®æ–‡æœ¬ API Key"
    
    if "DeepSeek" in provider:
        base_url, model = "https://api.deepseek.com", "deepseek-chat"
    elif "Moonshot" in provider:
        base_url, model = "https://api.moonshot.cn/v1", "moonshot-v1-8k"
    else:
        base_url, model = "https://api.openai.com/v1", "gpt-4o"

    client = OpenAI(api_key=key, base_url=base_url)
    
    system_prompt = """
    ä½ æ˜¯ä¸€åå°çº¢ä¹¦é‡‘ç‰Œè¿è¥ã€‚è¯·ç»“åˆã€è§†è§‰æè¿°ã€‘å’Œã€å•†å®¶è¡¥å……ä¿¡æ¯ã€‘ï¼Œå†™ä¸€ç¯‡æå…·è¯±æƒ‘åŠ›çš„å¤–å–ç§è‰ç¬”è®°ã€‚
    è¦æ±‚ï¼šæ ‡é¢˜äºŒæç®¡ï¼Œæ­£æ–‡å¤šEmojiï¼Œç—›ç‚¹åœºæ™¯åŒ–ï¼Œå¼•å¯¼ä¸‹å•ã€‚
    """
    
    user_prompt = f"""
    ã€AIè§†è§‰æè¿°ï¼ˆå›¾ç‰‡å†…å®¹ï¼‰ã€‘ï¼š{vision_analysis}
    ã€å•†å®¶è¡¥å……ä¿¡æ¯ï¼ˆä»·æ ¼/æ´»åŠ¨ï¼‰ã€‘ï¼š{user_topic}
    
    è¯·æ®æ­¤ç”Ÿæˆç¬”è®°ã€‚
    """
    
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )
    return response.choices[0].message.content

def refine_image(vision_analysis, provider_config):
    """ã€ç”»æ‰‹ã€‘å›¾ç‰‡ç²¾ä¿®ï¼šåŸºäºè§†è§‰æè¿°é‡ç»˜"""
    _, key = provider_config
    if not key: return "Error: æœªé…ç½®ç»˜å›¾ API Key"
    
    # 1. å…ˆæŠŠè§†è§‰æè¿°ç¿»è¯‘æˆè‹±æ–‡ Prompt (ç®€æ˜“ç‰ˆç›´æ¥ç”¨DeepSeekç¿»è¯‘ï¼Œè¿™é‡Œä¸ºäº†ä»£ç ç®€æ´ç›´æ¥æ„é€ )
    # åœ¨å®é™…æœ€ä½³å®è·µä¸­ï¼Œåº”è¯¥å…ˆè®© LLM ä¼˜åŒ– promptï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨å¢å¼ºæ¨¡æ¿
    magic_prompt = f"Professional food photography, 8k, masterpiece, {vision_analysis}, cinematic lighting, appetizing, high resolution, soft focus background"
    
    client = OpenAI(api_key=key, base_url="https://api.siliconflow.cn/v1")
    
    try:
        response = client.images.generate(
            model="black-forest-labs/FLUX.1-schnell",
            prompt=magic_prompt,
            size="1024x1024",
            n=1
        )
        return response.data[0].url
    except Exception as e:
        return f"Error: {str(e)}"

# --- 4. ä¸»ç•Œé¢å¸ƒå±€ ---

st.title("ğŸ”¥ çˆ†æ¬¾ç¬”è®°ç”Ÿæˆå™¨ (AIå¤šæ¨¡æ€ç‰ˆ)")
st.caption("è§†è§‰è¯†åˆ« + æ·±åº¦å†™ä½œ + ä»¿çœŸé‡ç»˜")

col_left, col_right = st.columns([1, 1.2], gap="large")

with col_left:
    st.markdown("### ğŸ“¸ ç´ æä¸Šä¼ ")
    uploaded_file = st.file_uploader("ä¸Šä¼ å•†å®¶å®æ‹å›¾", type=["jpg", "png", "jpeg"])
    if uploaded_file:
        st.image(uploaded_file, caption="åŸå§‹å›¾ç‰‡", use_container_width=True)

with col_right:
    st.markdown("### ğŸ“ è¡¥å……ä¿¡æ¯")
    user_topic = st.text_area("è¡¥å……ç»†èŠ‚ (å¿…å¡«)", height=100, placeholder="ä¾‹å¦‚ï¼šæ–°åº—å¼€ä¸šæ‰“8æŠ˜ï¼Œæ»¡20èµ·é€ï¼Œé€‚åˆåŠ ç­å…š...")
    
    start_btn = st.button("ğŸš€ å¼€å§‹å¤šæ¨¡æ€å…¨è‡ªåŠ¨ç”Ÿæˆ", type="primary", use_container_width=True)

st.divider()

# --- 5. æ‰§è¡Œé€»è¾‘ ---
if start_btn:
    if not uploaded_file:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ ä¸€å¼ å›¾ç‰‡ï¼Œè®© AI 'çœ‹' ä¸€ä¸‹ï¼")
    else:
        # 1. è§†è§‰åˆ†æé˜¶æ®µ
        with st.status("ğŸ‘ï¸ AI æ­£åœ¨è§‚å¯Ÿå›¾ç‰‡ç»†èŠ‚...", expanded=True) as status:
            st.write("æ­£åœ¨è¯†åˆ«èœå“ã€æ„å›¾ä¸å…‰å½±...")
            vision_result = analyze_image(uploaded_file, config["vision"])
            
            if "Error" in vision_result or "å¤±è´¥" in vision_result:
                st.error(vision_result)
                status.update(label="âŒ è§†è§‰è¯†åˆ«å¤±è´¥", state="error")
                st.stop()
            else:
                st.info(f"âœ… è§†è§‰è¯†åˆ«å®Œæˆï¼š{vision_result[:50]}...")
            
            # 2. æ–‡æ¡ˆç”Ÿæˆé˜¶æ®µ
            st.write("ğŸ§  æ­£åœ¨æ ¹æ®è§†è§‰ä¿¡æ¯æ’°å†™çˆ†æ¬¾æ–‡æ¡ˆ...")
            note_result = generate_copy(vision_result, user_topic, config["text"])
            
            # 3. å›¾ç‰‡ç²¾ä¿®é˜¶æ®µ
            st.write("ğŸ¨ FLUX æ­£åœ¨æ ¹æ®è§†è§‰ç†è§£é‡ç»˜å¤§ç‰‡...")
            refined_img_url = refine_image(vision_result, config["img"])
            
            status.update(label="âœ… å…¨æµç¨‹å®Œæˆï¼", state="complete", expanded=False)

        # --- 6. ç»“æœå±•ç¤º ---
        st.success("ğŸ‰ ç”ŸæˆæˆåŠŸï¼")
        
        res_col1, res_col2 = st.columns(2)
        
        with res_col1:
            st.markdown("#### ğŸ–¼ï¸ AI ç²¾ä¿®å¤§ç‰‡")
            if "http" in refined_img_url:
                st.image(refined_img_url, use_container_width=True)
                st.caption("ğŸ’¡ æç¤ºï¼šè¿™æ˜¯ AI åŸºäºåŸå›¾æ„å›¾é‡ç»˜çš„ 4K å›¾")
            else:
                st.error(refined_img_url)
                
        with res_col2:
            st.markdown("#### ğŸ“ çˆ†æ¬¾å°çº¢ä¹¦æ–‡æ¡ˆ")
            with st.container(border=True, height=500):
                st.markdown(note_result)
