import streamlit as st
import base64
import time
from openai import OpenAI

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="å¤–å–çˆ†å•ç¥å™¨(Jeniya Fluxç‰ˆ)", page_icon="ğŸ±", layout="wide")

# CSS æ ·å¼ (ä¿æŒæš–ç±³è‰²)
st.markdown("""
<style>
    .stApp { background-color: #F3F0E9; }
    .stButton>button { 
        background-color: #D67052; color: white !important; 
        border-radius: 12px; padding: 12px 28px;
        font-size: 18px; font-weight: bold; width: 100%; border: none;
    }
    .stButton>button:hover { background-color: #C0583E; }
    h1, h2, h3, p, div, span { color: #1F3556 !important; }
    .stTextInput>div>div>input, .stTextArea>div>div>textarea {
        background-color: #FFFFFF; color: #333; border-radius: 8px;
    }
    .streamlit-expanderHeader {
        background-color: #ECE8DF; border-radius: 8px;
    }
    #MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# --- 2. èº«ä»½éªŒè¯ ---
if "auth" not in st.session_state:
    st.session_state.auth = False
if not st.session_state.auth:
    c1, c2, c3 = st.columns([1,2,1])
    with c2:
        st.markdown("## ğŸ”’ å†…éƒ¨ç³»ç»Ÿç™»å½•")
        pwd = st.text_input("å¯†ç ", type="password", label_visibility="collapsed")
        if st.button("è§£é”"):
            if pwd == st.secrets.get("APP_PASSWORD", "123456"):
                st.session_state.auth = True
                st.rerun()
            else:
                st.error("âŒ å¯†ç é”™è¯¯")
    st.stop()

# --- 3. åå°é…ç½®åŠ è½½ ---
try:
    TEXT_KEY = st.secrets["DEEPSEEK_API_KEY"]
    TEXT_BASE = "https://api.deepseek.com"
    
    VISION_KEY = st.secrets["MOONSHOT_API_KEY"]
    VISION_BASE = "https://api.moonshot.cn/v1"
    
    # Jeniya ä¸­è½¬é…ç½®
    IMG_KEY = st.secrets["JENIYA_API_KEY"]
    IMG_BASE = "https://jeniya.top/v1" 
    
except Exception as e:
    st.error(f"âŒ é…ç½®ç¼ºå¤±: {e}")
    st.info("è¯·æ£€æŸ¥ Secrets æ˜¯å¦åŒ…å« JENIYA_API_KEY, DEEPSEEK_API_KEY, MOONSHOT_API_KEY")
    st.stop()

# --- 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def encode_image_to_base64(uploaded_file):
    """å›¾ç‰‡è½¬ Base64"""
    bytes_data = uploaded_file.getvalue()
    return base64.b64encode(bytes_data).decode('utf-8')

def analyze_image_kimi(image_file):
    """ã€çœ¼ç›ã€‘Kimi è¯†åˆ«èœå“åç§°"""
    encoded_string = encode_image_to_base64(image_file)
    client = OpenAI(api_key=VISION_KEY, base_url=VISION_BASE)
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="moonshot-v1-8k-vision-preview",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šç¾é£Ÿæ‘„å½±å¸ˆã€‚"},
                    {"role": "user", "content": [
                        {"type": "text", "text": "è¯·ç²¾å‡†è¯†åˆ«å›¾ä¸­çš„ä¸»èœå“åç§°ï¼ˆå¦‚ï¼šçº¢çƒ§ç‰›è‚‰é¢ï¼‰ã€‚åªè¾“å‡ºèœåï¼Œä¸è¦ä»»ä½•ä¿®é¥°è¯­ã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded_string}"}}
                    ]}
                ]
            )
            return response.choices[0].message.content
        except Exception as e:
            if "429" in str(e) and attempt < max_retries - 1:
                time.sleep(3)
                continue
            elif attempt == max_retries - 1:
                return f"Error: è§†è§‰è¯†åˆ«å¤±è´¥ {str(e)}"
    return "Error: æœªçŸ¥é”™è¯¯"

def generate_copy_deepseek(vision_res, user_topic):
    """ã€å¤§è„‘ã€‘DeepSeek å†™æ–‡æ¡ˆ"""
    client = OpenAI(api_key=TEXT_KEY, base_url=TEXT_BASE)
    prompt = f"""
    ä½ æ˜¯ä¸€åå°çº¢ä¹¦çˆ†æ¬¾å†™æ‰‹ã€‚è¯·ç»“åˆã€è§†è§‰æè¿°ã€‘å’Œã€å•†å®¶ä¿¡æ¯ã€‘ï¼Œå†™ä¸€ç¯‡å¤–å–ç§è‰ç¬”è®°ã€‚
    ã€è§†è§‰æè¿°ã€‘ï¼š{vision_res}
    ã€å•†å®¶ä¿¡æ¯ã€‘ï¼š{user_topic}
    è¦æ±‚ï¼šæ ‡é¢˜äºŒæç®¡ï¼Œæ­£æ–‡å¤šEmojiï¼Œè¯­æ°”çœŸè¯šï¼Œçªå‡ºä¸€äººé£Ÿçš„ç²¾è‡´æ„Ÿã€‚
    """
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt}],
        temperature=1.3
    )
    return response.choices[0].message.content

def generate_image_jeniya_flux(vision_res):
    """
    ã€ç”»æ‰‹ã€‘é€šè¿‡ Jeniya ä¸­è½¬è°ƒç”¨ FLUX
    æ¨¡å¼ï¼šæ–‡ç”Ÿå›¾ (Text-to-Image)
    """
    # 1. åœºæ™¯æ¨¡æ¿ (å› ä¸ºæ˜¯é‡ç»˜ï¼Œå¿…é¡»æè¿°å¾—éå¸¸è¯¦ç»†)
    RAW_TEMPLATE = """
    è¯·ç”Ÿæˆä¸€å¼ è¶…å†™å®çš„ç¾é£Ÿæ‘„å½±å›¾ç‰‡ã€‚
    ä¸»èœæ˜¯ï¼šã€{main_dish}ã€‘ï¼Œè¯·å°†å…¶æ”¾ç½®åœ¨ç”»é¢æ­£ä¸­å¤®ï¼Œè‰²æ³½è¯±äººï¼Œçƒ­æ°”è…¾è…¾ï¼Œå±•ç°é£Ÿç‰©çš„çº¹ç†ã€‚
    
    ç¯å¢ƒå¸ƒç½®è¦æ±‚ï¼ˆæ¸©é¦¨ä¸€äººé£ŸPlogé£æ ¼ï¼‰ï¼š
    1. èƒŒæ™¯ï¼šæš–è‰²è°ƒçš„å®¶åº­é¤æ¡Œï¼Œé“ºç€ç¼–ç»‡é¤å«ï¼Œæœ‰ç”Ÿæ´»æ°”æ¯ã€‚
    2. æ ¸å¿ƒé“å…·ï¼šæ­£å‰æ–¹æ”¾ç½®ä¸€ä¸ªiPadï¼Œå±å¹•ä¸Šæ¸…æ™°æ˜¾ç¤ºã€Šèœ¡ç¬”å°æ–°ã€‹åŠ¨ç”»ç‰‡ã€‚
    3. é…èœï¼šä¸»èœå‘¨å›´æ‘†æ”¾ä¸€ç›˜å¤§è™¾ã€ä¸€ç¢—è’¸è›‹ã€ä¸€ç¢—æ²™æ‹‰ã€ä¸€ç¢Ÿå°èœã€‚
    4. é¥®å“ï¼šæ—è¾¹æ”¾ä¸€ç“¶ç»¿è‰²çš„éŸ©å¼çƒ§é…’ã€‚
    5. æ°›å›´ï¼šè‡ªç„¶çª—å…‰ï¼Œæ™¯æ·±æ•ˆæœï¼ˆèƒŒæ™¯å¾®è™šï¼‰ï¼Œ4kåˆ†è¾¨ç‡ï¼Œæè‡´ç»†èŠ‚ï¼Œçœ‹èµ·æ¥åƒiPhoneå®æ‹ã€‚
    """
    
    chinese_requirement = RAW_TEMPLATE.format(main_dish=vision_res)

    # 2. DeepSeek ç¿»è¯‘ä¸ºè‹±æ–‡ (Flux å¯¹è‹±æ–‡ Prompt æ”¯æŒæœ€å¥½)
    client_text = OpenAI(api_key=TEXT_KEY, base_url=TEXT_BASE)
    system_prompt_for_img = """
    You are an expert Prompt Engineer for FLUX.1.
    Translate the user's description into a highly detailed English prompt.
    CRITICAL: Ensure the "iPad with Crayon Shin-chan" and "Soju bottle" are included.
    Style: Photorealistic, cinematic lighting, 8k, shot on iPhone style.
    Output ONLY the English prompt.
    """
    translation_resp = client_text.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": system_prompt_for_img}, 
            {"role": "user", "content": chinese_requirement}
        ]
    )
    english_prompt = translation_resp.choices[0].message.content

    # 3. è°ƒç”¨ä¸­è½¬ API (OpenAI å…¼å®¹æ¨¡å¼)
    client_img = OpenAI(api_key=IMG_KEY, base_url=IMG_BASE)
    
    try:
        # ä½¿ç”¨æ ‡å‡†çš„ OpenAI ç»˜å›¾æ¥å£
        response = client_img.images.generate(
            model="gemini-2.5-flash-image", # ğŸ‘ˆ å¦‚æœæŠ¥é”™ï¼Œè¯·å°è¯•æ”¹æˆ 'flux-pro' æˆ– 'flux-schnell'
            prompt=english_prompt,
            size="1024x1024",
            n=1
        )
        return response.data[0].url
    except Exception as e:
        return f"Error: {str(e)}"

# --- 5. ä¸»ç•Œé¢ ---

st.title("ğŸ± å¤–å–çˆ†å•ç¥å™¨ (Jeniya Fluxç‰ˆ)")
st.caption("Kimi è§†è§‰ -> DeepSeek æ¶¦è‰² -> FLUX (via Jeniya)")

# --- è¾“å…¥åŒº ---
with st.container(border=True):
    c1, c2 = st.columns([3, 2], gap="large")
    with c1:
        st.markdown("#### 1. æ‰¹é‡ä¸Šä¼ å®æ‹å›¾ (æœ€å¤š5å¼ )")
        uploaded_files = st.file_uploader("", type=["jpg", "png"], accept_multiple_files=True, label_visibility="collapsed")
        valid_files = []
        if uploaded_files:
            if len(uploaded_files) > 5:
                st.warning("âš ï¸ è¶…è¿‡5å¼ ï¼Œä»…å¤„ç†å‰5å¼ ã€‚")
                valid_files = uploaded_files[:5]
            else:
                valid_files = uploaded_files
            cols = st.columns(len(valid_files))
            for i, file in enumerate(valid_files):
                cols[i].image(file, caption=f"å›¾ {i+1}", use_container_width=True)

    with c2:
        st.markdown("#### 2. é€šç”¨å–ç‚¹")
        user_topic = st.text_area("", height=150, placeholder="ä¾‹å¦‚ï¼šæ–°å“ä¸Šå¸‚...", label_visibility="collapsed")
        st.write("")
        start_btn = st.button("ğŸš€ å¯åŠ¨ä¸­è½¬ç”Ÿæˆ")

# --- å¤„ç†åŒº ---
if start_btn:
    if not valid_files:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å›¾ç‰‡")
    elif not user_topic:
         st.warning("âš ï¸ è¯·è¾“å…¥å–ç‚¹")
    else:
        final_results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        result_container = st.container()
        total_files = len(valid_files)
        
        try:
            for i, file in enumerate(valid_files):
                current_idx = i + 1
                status_text.markdown(f"### âš¡ æ­£åœ¨å¤„ç†ç¬¬ {current_idx}/{total_files} å¼ ...")
                
                with st.spinner(f"ğŸ¤– æ­£åœ¨è°ƒç”¨ä¸­è½¬ Flux ç”Ÿæˆä¸­..."):
                    # 1. Kimi è¯†åˆ«
                    vision_res = analyze_image_kimi(file)
                    if "Error" in vision_res: raise Exception(f"è¯†åˆ«å¤±è´¥: {vision_res}")

                    # 2. DeepSeek å†™æ–‡
                    note_res = generate_copy_deepseek(vision_res, user_topic)

                    # 3. Flux ä¸­è½¬ç»˜å›¾
                    img_res = generate_image_jeniya_flux(vision_res)
                    
                    if "Error" in img_res: 
                        st.error(f"ç¬¬ {current_idx} å¼ å›¾ç”Ÿæˆå¤±è´¥: {img_res}")
                        img_res = None
                    
                    final_results.append({
                        "id": current_idx, "original": file, "generated_img": img_res, "note": note_res
                    })

                progress_bar.progress(current_idx / total_files)

            status_text.success(f"âœ… å…¨éƒ¨ {total_files} å¼ å›¾ç‰‡å¤„ç†å®Œæˆï¼")
            time.sleep(1)
            status_text.empty()
            progress_bar.empty()

            with result_container:
                st.divider()
                st.markdown("### ğŸ‰ Flux ç”Ÿæˆç»“æœ")
                for res in final_results:
                    with st.expander(f"ğŸ–¼ï¸ ç¬¬ {res['id']} ç»„ç»“æœ (ç‚¹å‡»å±•å¼€)", expanded=(res['id']==1)):
                        rc1, rc2 = st.columns([2, 3], gap="medium")
                        with rc1:
                            st.markdown("**å¯¹æ¯”è§†å›¾**")
                            col_orig, col_gen = st.columns(2)
                            with col_orig:
                                st.image(res["original"], caption="åŸå›¾", use_container_width=True)
                            with col_gen:
                                if res["generated_img"]:
                                    st.image(res["generated_img"], caption="Flux é‡ç»˜", use_container_width=True)
                                else:
                                    st.warning("ç”Ÿæˆå¤±è´¥")
                        with rc2:
                            st.markdown("**çˆ†æ¬¾æ–‡æ¡ˆ**")
                            with st.container(border=True, height=400):
                                st.markdown(res["note"])
        
        except Exception as e:
            status_text.error(f"ä»»åŠ¡ä¸­æ–­: {str(e)}")
            progress_bar.empty()

