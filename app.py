import streamlit as st
import base64
import time
from openai import OpenAI
import io

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="å¤–å–çˆ†å•ç¥å™¨(ç¨³å®šä¿®å¤ç‰ˆ)", page_icon="ğŸ±", layout="wide")

# CSS æ ·å¼
st.markdown("""
<style>
    .stApp { background-color: #F3F0E9; }
    .stButton>button { 
        background-color: #D67052; color: white !important; 
        border-radius: 12px; padding: 12px 28px;
        font-size: 18px; font-weight: bold; width: 100%; border: none;
    }
    .stButton>button:hover { background-color: #C0583E; }
    h1, h2, h3, p, div, span { color: #1F3556 !important; }
    .stTextInput>div>div>input, .stTextArea>div>div>textarea {
        background-color: #FFFFFF; color: #333; border-radius: 8px;
    }
    .streamlit-expanderHeader {
        background-color: #ECE8DF; border-radius: 8px;
    }
    .stSlider > div > div > div > div { color: #D67052; }
    #MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# --- 2. èº«ä»½éªŒè¯ ---
if "auth" not in st.session_state:
    st.session_state.auth = False
if not st.session_state.auth:
    c1, c2, c3 = st.columns([1,2,1])
    with c2:
        st.markdown("## ğŸ”’ å†…éƒ¨ç³»ç»Ÿç™»å½•")
        pwd = st.text_input("å¯†ç ", type="password", label_visibility="collapsed")
        if st.button("è§£é”"):
            if pwd == st.secrets.get("APP_PASSWORD", "123456"):
                st.session_state.auth = True
                st.rerun()
            else:
                st.error("âŒ å¯†ç é”™è¯¯")
    st.stop()

# --- 3. åå°é…ç½®åŠ è½½ ---
try:
    TEXT_KEY = st.secrets["DEEPSEEK_API_KEY"]
    TEXT_BASE = "https://api.deepseek.com"
    VISION_KEY = st.secrets["MOONSHOT_API_KEY"]
    VISION_BASE = "https://api.moonshot.cn/v1"
    IMG_KEY = st.secrets["SILICON_API_KEY"]
    IMG_BASE = "https://jeniya.top"
except Exception as e:
    st.error(f"âŒ é…ç½®ç¼ºå¤±: {e}")
    st.stop()

# --- 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def encode_image_to_base64(uploaded_file):
    """å›¾ç‰‡è½¬ Base64"""
    bytes_data = uploaded_file.getvalue()
    return base64.b64encode(bytes_data).decode('utf-8')

def analyze_image_kimi(image_file):
    """ã€çœ¼ç›ã€‘Kimi è¯†åˆ«èœå“"""
    encoded_string = encode_image_to_base64(image_file)
    client = OpenAI(api_key=VISION_KEY, base_url=VISION_BASE)
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="moonshot-v1-8k-vision-preview",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šç¾é£Ÿæ‘„å½±å¸ˆã€‚"},
                    {"role": "user", "content": [
                        {"type": "text", "text": "è¯·ç²¾å‡†è¯†åˆ«å›¾ä¸­çš„ä¸»èœå“åç§°ï¼ˆå¦‚ï¼šçº¢çƒ§ç‰›è‚‰é¢ï¼‰ã€‚åªè¾“å‡ºèœåã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded_string}"}}
                    ]}
                ]
            )
            return response.choices[0].message.content
        except Exception as e:
            if "429" in str(e) and attempt < max_retries - 1:
                time.sleep(3)
                continue
            elif attempt == max_retries - 1:
                return f"Error: è§†è§‰è¯†åˆ«å¤±è´¥ {str(e)}"
    return "Error: æœªçŸ¥é”™è¯¯"

def generate_copy_deepseek(vision_res, user_topic):
    """ã€å¤§è„‘ã€‘DeepSeek å†™æ–‡æ¡ˆ"""
    client = OpenAI(api_key=TEXT_KEY, base_url=TEXT_BASE)
    prompt = f"""
    ä½ æ˜¯ä¸€åå°çº¢ä¹¦çˆ†æ¬¾å†™æ‰‹ã€‚è¯·ç»“åˆã€è§†è§‰æè¿°ã€‘å’Œã€å•†å®¶ä¿¡æ¯ã€‘ï¼Œå†™ä¸€ç¯‡å¤–å–ç§è‰ç¬”è®°ã€‚
    ã€è§†è§‰æè¿°ã€‘ï¼š{vision_res}
    ã€å•†å®¶ä¿¡æ¯ã€‘ï¼š{user_topic}
    è¦æ±‚ï¼šæ ‡é¢˜äºŒæç®¡ï¼Œæ­£æ–‡å¤šEmojiï¼Œè¯­æ°”çœŸè¯šï¼Œçªå‡ºä¸€äººé£Ÿçš„ç²¾è‡´æ„Ÿã€‚
    """
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt}],
        temperature=1.3
    )
    return response.choices[0].message.content

def generate_image_flux_img2img(uploaded_file, vision_res, strength):
    """
    ã€ç”»æ‰‹ã€‘FLUX.1-schnell å›¾ç”Ÿå›¾ (ä¿®å¤ç‰ˆ)
    æ ¸å¿ƒä¿®æ”¹ï¼šåˆ‡æ¢å› Schnell æ¨¡å‹ï¼Œä¿è¯ 100% æˆåŠŸç‡
    """
    img_base64 = encode_image_to_base64(uploaded_file)
    img_data_uri = f"data:image/png;base64,{img_base64}"

    # åœºæ™¯æ¨¡æ¿
    RAW_TEMPLATE = """
    åŸºäºè¾“å…¥åŸå›¾çš„ä¸»ä½“ã€{main_dish}ã€‘è¿›è¡Œé‡ç»˜ã€‚
    è¯·ä¿æŒç”»é¢ä¸­å¿ƒçš„ä¸»èœã€{main_dish}ã€‘ä¸åŸå›¾ä¸€è‡´ã€‚
    å°†èƒŒæ™¯æ›¿æ¢ä¸ºæ—¥å¸¸åˆ†äº«é£æ ¼çš„plogåœºæ™¯ï¼Œæš–è‰²è°ƒã€‚
    ç»†èŠ‚è¦æ±‚ï¼š
    1ã€æ¡Œé¢å¸ƒç½®ï¼šé“ºæœ‰ç¼–ç»‡é¤å«ï¼Œé¤å«æ—æ‘†æ”¾ç»¿æ¤ã€æ—¥å¼å¯çˆ±æ‘†ä»¶ã€ç‰™ç­¾ç›’ã€é¤å·¾çº¸ç›’ï¼›åœºæ™¯æ­£å‰æ–¹æ”¾ç½®1å°iPadï¼Œå±å¹•éœ€æ˜¾ç¤ºã€Šèœ¡ç¬”å°æ–°ã€‹æ’­æ”¾ç”»é¢ã€‚
    2ã€é¤é£Ÿæ­é…ï¼šä»¥ã€{main_dish}ã€‘ä¸ºCä½ï¼Œå‘¨å›´å›´ç»•æ‘†æ”¾ï¼š1ç›˜è‰²æ³½è¯±äººçš„å¤§è™¾ï¼Œ1ç¢—é²œå«©è’¸è›‹ï¼Œ1ç¢—è”¬èœæ²™æ‹‰ï¼Œ1ç›˜æ—¥å¼å°èœï¼Œ1ç“¶éŸ©å¼çƒ§é…’ã€‚
    3ã€è¾…åŠ©ç»†èŠ‚ï¼šå³ä¾§æ”¾ç½®æ—¥å¼ç­·æ¶ã€ç­·å­å’Œå‹ºå­ã€‚å…‰å½±æŸ”å’Œè‡ªç„¶ï¼Œ8ké«˜æ¸…åˆ†è¾¨ç‡ã€‚
    """
    chinese_requirement = RAW_TEMPLATE.format(main_dish=vision_res)

    # DeepSeek ç¿»è¯‘
    client_text = OpenAI(api_key=TEXT_KEY, base_url=TEXT_BASE)
    system_prompt_for_img = """
    You are an expert Prompt Engineer for FLUX.1 Image-to-Image.
    Translate the Chinese request into a detailed English prompt.
    CRITICAL: 
    1. You must describe the new background items (iPad with Crayon Shin-chan, Soju, woven mat) clearly.
    2. Emphasize that the main food subject comes from the input image.
    Output ONLY the English prompt.
    """
    translation_resp = client_text.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": system_prompt_for_img}, 
            {"role": "user", "content": chinese_requirement}
        ]
    )
    english_prompt = translation_resp.choices[0].message.content

    # è°ƒç”¨ FLUX (åˆ‡æ¢ä¸º schnell)
    client_img = OpenAI(api_key=IMG_KEY, base_url=IMG_BASE)
    try:
        response = client_img.images.generate(
            # ğŸ‘‡ æ ¸å¿ƒä¿®å¤ï¼šæ”¹å› schnellï¼Œç¨³å¦‚è€ç‹—
            model="gemini-3-pro-image-preview",
            prompt=english_prompt,
            size="1024x1024",
            n=1,
            extra_body={
                "image": img_data_uri,
                "strength": strength 
            }
        )
        return response.data[0].url
    except Exception as e:
        return f"Error: {str(e)}"

# --- 5. ä¸»ç•Œé¢ ---

st.title("ğŸ± å¤–å–çˆ†å•ç¥å™¨ (æé€Ÿä¿®å¤ç‰ˆ)")
st.caption("ä¸Šä¼ å®æ‹å›¾ -> è®¾å®šé‡ç»˜å¹…åº¦ -> æé€Ÿå›¾ç”Ÿå›¾")

# --- è¾“å…¥åŒº ---
with st.container(border=True):
    c1, c2 = st.columns([3, 2], gap="large")
    with c1:
        st.markdown("#### 1. æ‰¹é‡ä¸Šä¼ å®æ‹å›¾ (æœ€å¤š5å¼ )")
        uploaded_files = st.file_uploader("", type=["jpg", "png"], accept_multiple_files=True, label_visibility="collapsed")
        valid_files = []
        if uploaded_files:
            if len(uploaded_files) > 5:
                st.warning("âš ï¸ è¶…è¿‡5å¼ ï¼Œä»…å¤„ç†å‰5å¼ ã€‚")
                valid_files = uploaded_files[:5]
            else:
                valid_files = uploaded_files
            cols = st.columns(len(valid_files))
            for i, file in enumerate(valid_files):
                cols[i].image(file, caption=f"å›¾ {i+1}", use_container_width=True)

    with c2:
        st.markdown("#### 2. æ§åˆ¶ä¸å–ç‚¹")
        st.markdown("##### ğŸ¨ é‡ç»˜å¹…åº¦")
        strength = st.slider(
            "æ¨è 0.65 - 0.75",
            min_value=0.1, max_value=1.0, value=0.70, step=0.05,
            help="æ•°å€¼è¶Šå¤§ï¼ŒAI æ”¹åŠ¨è¶Šå¤š"
        )
        st.markdown("##### ğŸ“ é€šç”¨å–ç‚¹")
        user_topic = st.text_area("", height=100, placeholder="ä¾‹å¦‚ï¼šæ–°å“ä¸Šå¸‚...", label_visibility="collapsed")
        st.write("")
        start_btn = st.button("ğŸš€ å¯åŠ¨ä»»åŠ¡")

# --- å¤„ç†åŒº ---
if start_btn:
    if not valid_files:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å›¾ç‰‡")
    elif not user_topic:
         st.warning("âš ï¸ è¯·è¾“å…¥å–ç‚¹")
    else:
        final_results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        result_container = st.container()
        total_files = len(valid_files)
        
        try:
            for i, file in enumerate(valid_files):
                current_idx = i + 1
                status_text.markdown(f"### âš¡ æ­£åœ¨å¤„ç†ç¬¬ {current_idx}/{total_files} å¼ ...")
                
                with st.spinner(f"ğŸ¤– Kimiè¯†åˆ« -> FLUXæé€Ÿé‡ç»˜ä¸­..."):
                    vision_res = analyze_image_kimi(file)
                    if "Error" in vision_res: raise Exception(f"è¯†åˆ«å¤±è´¥: {vision_res}")

                    note_res = generate_copy_deepseek(vision_res, user_topic)

                    img_res = generate_image_flux_img2img(file, vision_res, strength)
                    if "Error" in img_res: raise Exception(f"ç”Ÿæˆå¤±è´¥: {img_res}")
                    
                    final_results.append({
                        "id": current_idx, "original": file, "generated_img": img_res, "note": note_res
                    })

                progress_bar.progress(current_idx / total_files)

            status_text.success(f"âœ… å…¨éƒ¨å®Œæˆï¼")
            time.sleep(1)
            status_text.empty()
            progress_bar.empty()

            with result_container:
                st.divider()
                st.markdown(f"### ğŸ‰ å¤„ç†ç»“æœ")
                for res in final_results:
                    with st.expander(f"ğŸ–¼ï¸ ç¬¬ {res['id']} ç»„ç»“æœ (ç‚¹å‡»å±•å¼€)", expanded=(res['id']==1)):
                        rc1, rc2 = st.columns([2, 3], gap="medium")
                        with rc1:
                            st.markdown("**å¯¹æ¯”è§†å›¾**")
                            col_orig, col_gen = st.columns(2)
                            with col_orig:
                                st.image(res["original"], caption="åŸå›¾", use_container_width=True)
                            with col_gen:
                                st.image(res["generated_img"], caption="AI é‡ç»˜å›¾", use_container_width=True)
                        with rc2:
                            st.markdown("**çˆ†æ¬¾æ–‡æ¡ˆ**")
                            with st.container(border=True, height=400):
                                st.markdown(res["note"])
        
        except Exception as e:
            status_text.error(f"ä»»åŠ¡ä¸­æ–­: {str(e)}")
            progress_bar.empty()

